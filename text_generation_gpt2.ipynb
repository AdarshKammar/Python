{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdarshKammar/Python/blob/main/text_generation_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "qmP1goPjvy1c",
        "outputId": "1ccad716-8388-43d3-bef5-bb1418adc1aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "import textwrap  # For text wrapping (if needed)\n",
        "from IPython.display import HTML  # For HTML text area (if needed)\n",
        "\n",
        "model_name = \"gpt2\"  # Or any other suitable model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "prompt = \"What is AI.\"\n",
        "\n",
        "# Generation config with beam search\n",
        "generation_config_beam = {\n",
        "    \"max_length\": 150,\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_k\": 50,\n",
        "    \"top_p\": 0.95,\n",
        "    \"repetition_penalty\": 1.2,\n",
        "    \"num_beams\": 3,\n",
        "    \"early_stopping\": True\n",
        "}\n",
        "\n",
        "generated_text_beam = generator(prompt, **generation_config_beam)[0]['generated_text']\n",
        "\n",
        "# 1. Colab's Built-in Wrapping (Simplest - Try this first):\n",
        "print(\"Generated Text (Beam Search - Colab Wrapping):\\n\", generated_text_beam)\n",
        "print(\"-\" * 80)  # Separator\n",
        "\n",
        "# 2. Using textwrap (If Colab wrapping isn't sufficient):\n",
        "wrapped_beam_text = textwrap.fill(generated_text_beam, width=80) # Adjust width as needed\n",
        "print(\"Generated Text (Beam Search - textwrap):\\n\", wrapped_beam_text)\n",
        "print(\"-\" * 80) # Separator\n",
        "\n",
        "\n",
        "# 3. HTML Text Area (For maximum control):\n",
        "html_code_beam = f\"\"\"\n",
        "<textarea rows=\"10\" cols=\"80\" style=\"width: 95%; height: 200px; overflow: auto;\">  {generated_text_beam}\n",
        "</textarea>\n",
        "\"\"\"\n",
        "display(HTML(html_code_beam))\n",
        "print(\"-\" * 80) # Separator\n",
        "\n"
      ],
      "metadata": {
        "id": "b5avHHCEx_4J",
        "outputId": "b86be327-c9ad-4bc8-c990-ecfce3596e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text (Beam Search - Colab Wrapping):\n",
            " What is AI.\n",
            "\n",
            "AI is the ability to understand and interact with the world around us. It's the ability to understand and interact with the human mind. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain.\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Text (Beam Search - textwrap):\n",
            " What is AI.  AI is the ability to understand and interact with the world around\n",
            "us. It's the ability to understand and interact with the human mind. It's the\n",
            "ability to understand and interact with the human brain. It's the ability to\n",
            "understand and interact with the human brain. It's the ability to understand and\n",
            "interact with the human brain. It's the ability to understand and interact with\n",
            "the human brain. It's the ability to understand and interact with the human\n",
            "brain. It's the ability to understand and interact with the human brain. It's\n",
            "the ability to understand and interact with the human brain. It's the ability to\n",
            "understand and interact with the human brain. It's the ability to understand and\n",
            "interact with the human brain.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<textarea rows=\"10\" cols=\"80\" style=\"width: 95%; height: 200px; overflow: auto;\">  What is AI.\n",
              "\n",
              "AI is the ability to understand and interact with the world around us. It's the ability to understand and interact with the human mind. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain. It's the ability to understand and interact with the human brain.\n",
              "</textarea>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generation config without beam search (Same options as above)\n",
        "generation_config_no_beam = {\n",
        "    \"max_length\": 150,\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_k\": 50,\n",
        "    \"top_p\": 0.95,\n",
        "    \"repetition_penalty\": 1.2,\n",
        "}\n",
        "\n",
        "generated_text_no_beam = generator(prompt, **generation_config_no_beam)[0]['generated_text']\n",
        "\n",
        "\n",
        "print(\"Generated Text (No Beam Search - Colab Wrapping):\\n\", generated_text_no_beam)\n",
        "print(\"-\" * 80) # Separator\n",
        "\n",
        "wrapped_no_beam_text = textwrap.fill(generated_text_no_beam, width=80)\n",
        "print(\"Generated Text (No Beam Search - textwrap):\\n\", wrapped_no_beam_text)\n",
        "print(\"-\" * 80) # Separator\n",
        "\n",
        "html_code_no_beam = f\"\"\"\n",
        "<textarea rows=\"10\" cols=\"80\" style=\"width: 95%; height: 200px; overflow: auto;\">\n",
        "{generated_text_no_beam}\n",
        "</textarea>\n",
        "\"\"\"\n",
        "display(HTML(html_code_no_beam))"
      ],
      "metadata": {
        "id": "56ObWlbSyFPx",
        "outputId": "d6180dd0-f8dd-4641-e39b-e5669194a8f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text (No Beam Search - Colab Wrapping):\n",
            " What is AI. What are its goals?\n",
            "A machine learning algorithm can learn a lot of things, but most algorithms (i) don't do anything useful for human needs or behavioral problems and b] they aren-as far as humans know it's not doing any good at all in general! So the goal here isn' to have one thing that has some effect on us; how we should use our power if there was no other way - something like an intelligent computer program with multiple user interfaces: what might this be called? Why wouldn 'a system based upon your own strengths'. We want machines designed specifically so when people need help them will go about solving their problem efficiently using those tools available by ourselves which would then benefit everyone else too :\n",
            "--------------------------------------------------------------------------------\n",
            "Generated Text (No Beam Search - textwrap):\n",
            " What is AI. What are its goals? A machine learning algorithm can learn a lot of\n",
            "things, but most algorithms (i) don't do anything useful for human needs or\n",
            "behavioral problems and b] they aren-as far as humans know it's not doing any\n",
            "good at all in general! So the goal here isn' to have one thing that has some\n",
            "effect on us; how we should use our power if there was no other way - something\n",
            "like an intelligent computer program with multiple user interfaces: what might\n",
            "this be called? Why wouldn 'a system based upon your own strengths'. We want\n",
            "machines designed specifically so when people need help them will go about\n",
            "solving their problem efficiently using those tools available by ourselves which\n",
            "would then benefit everyone else too :\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<textarea rows=\"10\" cols=\"80\" style=\"width: 95%; height: 200px; overflow: auto;\">\n",
              "What is AI. What are its goals?\n",
              "A machine learning algorithm can learn a lot of things, but most algorithms (i) don't do anything useful for human needs or behavioral problems and b] they aren-as far as humans know it's not doing any good at all in general! So the goal here isn' to have one thing that has some effect on us; how we should use our power if there was no other way - something like an intelligent computer program with multiple user interfaces: what might this be called? Why wouldn 'a system based upon your own strengths'. We want machines designed specifically so when people need help them will go about solving their problem efficiently using those tools available by ourselves which would then benefit everyone else too :\n",
              "</textarea>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}